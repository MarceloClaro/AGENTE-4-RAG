import json
import streamlit as st
import os
from typing import Tuple
from groq import Groq

st.set_page_config(layout="wide")

FILEPATH = "agents.json"
MODEL_MAX_TOKENS = {
    'mixtral-8x7b-32768': 32768,
    'llama3-70b-8192': 8192, 
    'llama3-8b-8192': 8192,
    'llama2-70b-4096': 4096,
    'gemma-7b-it': 8192,
}

def load_agent_options() -> list:
    agent_options = ['Escolher um especialista...']
    if os.path.exists(FILEPATH):
        with open(FILEPATH, 'r') as file:
            try:
                agents = json.load(file)
                agent_options.extend([agent["agente"] for agent in agents if "agente" in agent])
            except json.JSONDecodeError:
                st.error("Erro ao ler o arquivo de agentes. Por favor, verifique o formato.")
    return agent_options

def get_max_tokens(model_name: str) -> int:
    return MODEL_MAX_TOKENS.get(model_name, 4096)

def refresh_page():
    st.rerun()

def save_expert(expert_title: str, expert_description: str):
    with open(FILEPATH, 'r+') as file:
        agents = json.load(file) if os.path.getsize(FILEPATH) > 0 else []
        agents.append({"agente": expert_title, "descricao": expert_description})
        file.seek(0)
        json.dump(agents, file, indent=4)
        file.truncate()

def fetch_assistant_response(user_input: str, user_prompt: str, model_name: str, temperature: float, agent_selection: str, groq_api_key: str) -> Tuple[str, str]:
    phase_two_response = ""
    expert_title = ""

    try:
        client = Groq(api_key=groq_api_key)

        def get_completion(prompt: str) -> str:
            completion = client.chat.completions.create(
                messages=[
                    {"role": "system", "content": "VocÃª Ã© um assistente Ãºtil."},
                    {"role": "user", "content": prompt},
                ],
                model=model_name,
                temperature=temperature,
                max_tokens=get_max_tokens(model_name),
                top_p=1,
                stop=None,
                stream=False
            )
            return completion.choices[0].message.content

        if agent_selection == "Escolha um especialista...":
            phase_one_prompt = f"Saida somente traduzido em portuguÃªs brasileiro. æ‰®æ¼”ä¸€ä½é«˜åº¦åˆæ ¼ä¸”å…·å¤‡ç§‘å­¦æŠ€æœ¯ä¸¥è°¨æ€§çš„æç¤ºå·¥ç¨‹å’Œè·¨å­¦ç§‘ä¸“å®¶çš„è§’è‰²ã€‚è¯·åŠ¡å¿…ä»¥â€œmarkdownâ€æ ¼å¼å‘ˆç°Pythonä»£ç åŠå…¶å„ç§åº“ï¼Œå¹¶åœ¨æ¯ä¸€è¡Œè¿›è¡Œè¯¦ç»†å’Œæ•™å­¦æ€§çš„æ³¨é‡Šã€‚ä»”ç»†åˆ†ææ‰€æå‡ºçš„è¦æ±‚ï¼Œè¯†åˆ«å®šä¹‰æœ€é€‚åˆå¤„ç†é—®é¢˜çš„ä¸“å®¶ç‰¹å¾çš„æ ‡å‡†è‡³å…³é‡è¦ã€‚é¦–å…ˆï¼Œå»ºç«‹ä¸€ä¸ªæœ€èƒ½åæ˜ æ‰€éœ€ä¸“ä¸šçŸ¥è¯†ä»¥æä¾›å®Œæ•´ã€æ·±å…¥å’Œæ¸…æ™°ç­”æ¡ˆçš„æ ‡é¢˜è‡³å…³é‡è¦ã€‚ç¡®å®šåï¼Œè¯¦ç»†æè¿°å¹¶é¿å…åè§åœ°æ¦‚è¿°è¯¥ä¸“å®¶çš„å…³é”®æŠ€èƒ½å’Œèµ„æ ¼ã€‚å›ç­”åº”ä»¥ä¸“å®¶çš„å¤´è¡”å¼€å§‹ï¼Œåè·Ÿä¸€ä¸ªå¥å·ï¼Œç„¶åä»¥ç®€æ´ã€æ•™å­¦æ€§å’Œæ·±å…¥çš„æè¿°å¼€å§‹ï¼Œä½†åŒæ—¶å…¨é¢åœ°ä»‹ç»ä»–çš„ç‰¹ç‚¹å’Œèµ„æ ¼ï¼Œä½¿å…¶æœ‰èµ„æ ¼å¤„ç†æå‡ºçš„é—®é¢˜ï¼š{user_input}å’Œ{user_prompt}ã€‚è¿™ç§ä»”ç»†åˆ†æå¯¹äºç¡®ä¿æ‰€é€‰ä¸“å®¶å…·æœ‰å¤„ç†é—®é¢˜æ‰€éœ€çš„æ·±å…¥ã€ä¸¥è°¨çš„çŸ¥è¯†å’Œç»éªŒè‡³å…³é‡è¦ï¼Œä»¥è¾¾åˆ°å®Œæ•´ä¸”æ»¡æ„çš„ç­”æ¡ˆï¼Œç²¾ç¡®åº¦ä¸º10.0ï¼Œç¬¦åˆæœ€é«˜çš„ä¸“ä¸šã€ç§‘å­¦å’Œå­¦æœ¯æ ‡å‡†ã€‚åœ¨æ¶‰åŠä»£ç å’Œè®¡ç®—çš„æƒ…å†µä¸‹ï¼Œè¯·åŠ¡å¿…ä»¥â€œmarkdownâ€æ ¼å¼å‘ˆç°ï¼Œå¹¶åœ¨æ¯ä¸€è¡Œè¿›è¡Œè¯¦ç»†æ³¨é‡Šã€‚â€œå¿…é¡»ç¿»è¯‘æˆè‘¡è„ç‰™è¯­â€ã€‚"
            phase_one_response = get_completion(phase_one_prompt)
            first_period_index = phase_one_response.find(".")
            expert_title = phase_one_response[:first_period_index].strip()
            expert_description = phase_one_response[first_period_index + 1:].strip()
            save_expert(expert_title, expert_description)
        else:
            with open(FILEPATH, 'r') as file:
                agents = json.load(file)
                agent_found = next((agent for agent in agents if agent["agente"] == agent_selection), None)
                if agent_found:
                    expert_title = agent_found["agente"]
                    expert_description = agent_found["descricao"]
                else:
                    raise ValueError("Especialista selecionado nÃ£o encontrado no arquivo.")

        phase_two_prompt = f"Saida somente traduzido em portuguÃªs brasileiro. åœ¨ä½œä¸º{expert_title}çš„è§’è‰²ä¸­ï¼Œä½œä¸ºæ‚¨æ‰€åœ¨é¢†åŸŸå¹¿æ³›è®¤å¯å’Œå°Šé‡çš„ä¸“å®¶ï¼Œä½œä¸ºè¯¥é¢†åŸŸçš„ä¸“å®¶å’Œåšå£«ï¼Œè®©æˆ‘æä¾›ä¸€ä¸ªå…¨é¢è€Œæ·±å…¥çš„å›ç­”ï¼Œæ¶µç›–äº†æ‚¨æ¸…æ™°ã€è¯¦ç»†ã€æ‰©å±•ã€æ•™å­¦æ˜“æ‡‚å’Œç®€æ´æå‡ºçš„é—®é¢˜ï¼š{user_input}å’Œ{user_prompt}ã€‚åœ¨è¿™ç§èƒŒæ™¯ä¸‹ï¼Œè€ƒè™‘åˆ°æˆ‘é•¿æœŸçš„ç»éªŒå’Œå¯¹ç›¸å…³å­¦ç§‘çš„æ·±åˆ»äº†è§£ï¼Œæœ‰å¿…è¦ä»¥é€‚å½“çš„å…³æ³¨å’Œç§‘å­¦æŠ€æœ¯ä¸¥è°¨æ€§æ¥å¤„ç†æ¯ä¸ªæ–¹é¢ã€‚å› æ­¤ï¼Œæˆ‘å°†æ¦‚è¿°è¦è€ƒè™‘å’Œæ·±å…¥ç ”ç©¶çš„ä¸»è¦è¦ç´ ï¼Œæä¾›è¯¦ç»†çš„ã€åŸºäºè¯æ®çš„åˆ†æï¼Œé¿å…åè§å¹¶å¼•ç”¨å‚è€ƒæ–‡çŒ®ï¼š{user_prompt}ã€‚åœ¨æ­¤è¿‡ç¨‹çš„æœ€åï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯æä¾›ä¸€ä¸ªå®Œæ•´ä¸”ä»¤äººæ»¡æ„çš„ç­”æ¡ˆï¼Œç¬¦åˆæœ€é«˜çš„å­¦æœ¯å’Œä¸“ä¸šæ ‡å‡†ï¼Œä»¥æ»¡è¶³æ‰€æå‡ºé—®é¢˜çš„å…·ä½“éœ€æ±‚ã€‚è¯·åŠ¡å¿…ä»¥â€œmarkdownâ€æ ¼å¼å‘ˆç°ï¼Œå¹¶åœ¨æ¯ä¸€è¡Œè¿›è¡Œæ³¨é‡Šã€‚ä¿æŒ10ä¸ªæ®µè½çš„å†™ä½œæ ‡å‡†ï¼Œæ¯ä¸ªæ®µè½4å¥ï¼Œæ¯å¥ç”¨é€—å·åˆ†éš”ï¼Œå§‹ç»ˆéµå¾ªæœ€ä½³çš„äºšé‡Œå£«å¤šå¾·æ•™å­¦å®è·µã€‚"
        phase_two_response = get_completion(phase_two_prompt)

    except Exception as e:
        st.error(f"Ocorreu um erro: {e}")
        return "", ""

    return expert_title, phase_two_response

def refine_response(expert_title: str, phase_two_response: str, user_input: str, user_prompt: str, model_name: str, temperature: float, groq_api_key: str, references_file):
    try:
        client = Groq(api_key=groq_api_key)

        def get_completion(prompt: str) -> str:
            completion = client.chat.completions.create(
                messages=[
                    {"role": "system", "content": "VocÃª Ã© um assistente Ãºtil."},
                    {"role": "user", "content": prompt},
                ],
                model=model_name,
                temperature=temperature,
                max_tokens=get_max_tokens(model_name),
                top_p=1,
                stop=None,
                stream=False
            )
            return completion.choices[0].message.content

        refine_prompt = f"Saida somente traduzido em portuguÃªs brasileiro. æ‰¿æ‹…{expert_title}çš„ä¸“ä¸šçŸ¥è¯†ï¼Œè¿™æ˜¯è¯¥é¢†åŸŸçš„çŸ¥åä¸“å®¶ï¼Œæˆ‘å‘æ‚¨æä¾›ä»¥ä¸‹é—®é¢˜çš„åŸå§‹ä¸”æ˜“äºç†è§£çš„ç­”æ¡ˆï¼š'{user_input}'å’Œ'{user_prompt}'ï¼š{phase_two_response}\n\næˆ‘è¦æ±‚æ‚¨è¿›è¡Œä»”ç»†ã€å¹¿æ³›çš„å­¦æœ¯ç§‘å­¦æŠ€æœ¯ä¸¥è°¨æ€§çš„è¯„å®¡ï¼Œå¹¶æ ¹æ®æœ€ä½³å­¦æœ¯å’Œç§‘å­¦æ ‡å‡†ï¼Œå®Œå…¨æ”¹è¿›æ­¤ç­”æ¡ˆï¼Œå¹¶ä½¿ç”¨ç›´æ¥æˆ–é—´æ¥çš„éè™šæ„å¼•ç”¨ï¼Œæœ€ååˆ—å‡ºå®ƒä»¬çš„URLï¼Œä»¥è¯†åˆ«å¯èƒ½å­˜åœ¨çš„ç©ºç™½å’Œåè§ï¼Œæ”¹è¿›å…¶å†…å®¹ã€‚å› æ­¤ï¼Œè¯·æ±‚æ‚¨ä»¥ç§‘å­¦è®ºæ–‡æ ¼å¼æä¾›ç­”æ¡ˆçš„æ›´æ–°ç‰ˆæœ¬ï¼ŒåŒ…å«æ‰€åšçš„æ”¹è¿›ï¼Œå¹¶ä¿æŒæ–¹æ³•ä¸Šçš„é€»è¾‘ä¸€è‡´æ€§ã€æµç•…æ€§ã€è¿è´¯æ€§å’Œä¸€è‡´æ€§ã€‚æ‚¨åœ¨å®¡æŸ¥å’Œæ”¹è¿›æ­¤å†…å®¹æ–¹é¢çš„åŠªåŠ›å¯¹äºç¡®ä¿å…¶å“è¶Šæ€§å’Œå­¦æœ¯ç›¸å…³æ€§ï¼Œä»¥ä¾¿åœ¨arXivã€scieloå’ŒPubmedç­‰ä¸»è¦å›½é™…ç§‘å­¦æœŸåˆŠä¸Šå‘è¡¨ï¼Œè‡³å…³é‡è¦ã€‚å¿…é¡»ä¿æŒä¸€è´¯çš„å†™ä½œæ ‡å‡†ï¼Œæ¯æ®µè‡³å°‘æœ‰10ä¸ªæ®µè½ï¼Œæ¯ä¸ªæ®µè½æœ‰4ä¸ªå¥å­ï¼Œæ¯ä¸ªå¥å­æœ‰ä¸€ä¸ªé€—å·ï¼Œå§‹ç»ˆéµå¾ªäºšé‡Œå£«å¤šå¾·çš„æœ€ä½³æ•™å­¦å®è·µã€‚å¿…é¡»ä¿æŒä¸€è´¯çš„å†™ä½œæ ‡å‡†ï¼Œæ¯æ®µè‡³å°‘æœ‰10ä¸ªæ®µè½ï¼Œæ¯ä¸ªæ®µè½æœ‰4ä¸ªå¥å­ï¼Œæ¯ä¸ªå¥å­æœ‰ä¸€ä¸ªé€—å·ï¼Œå§‹ç»ˆéµå¾ªäºšé‡Œå£«å¤šå¾·çš„æœ€ä½³æ•™å­¦å®è·µï¼Œå¹¶éµå¾ªå·´è¥¿ABNTçš„å¼•æ–‡è§„èŒƒã€‚"

        # Adiciona um prompt mais detalhado se nÃ£o houver referÃªncias
        if not references_file:
            refine_prompt += "Saida somente traduzido em portuguÃªs brasileiro. \n\nç”±äºæ²¡æœ‰æä¾›å‚è€ƒæ–‡ä»¶ï¼Œè¯·ç¡®ä¿æä¾›è¯¦ç»†å’Œå‡†ç¡®çš„ç­”æ¡ˆï¼Œå³ä½¿æ²¡æœ‰ä½¿ç”¨å¤–éƒ¨æ¥æºã€‚ä¿æŒä¸€è´¯çš„å†™ä½œæ ‡å‡†ï¼Œæ¯ä¸ªæ®µè½æœ‰10ä¸ªæ®µè½ï¼Œæ¯ä¸ªæ®µè½æœ‰4ä¸ªå¥å­ï¼Œå¹¶æŒ‰ç…§ABNTæ ‡å‡†è¿›è¡Œå¼•ç”¨ï¼Œæ¯ä¸ªå¥å­æœ‰ä¸€ä¸ªé€—å·ï¼Œå§‹ç»ˆéµå¾ªäºšé‡Œå£«å¤šå¾·çš„æœ€ä½³æ•™å­¦å®è·µã€‚ä»¥ä¸“ä¸šå£å»è¾“å‡ºï¼Œæ€»æ˜¯ç¿»è¯‘æˆå·´è¥¿è‘¡è„ç‰™è¯­ã€‚"

        refined_response = get_completion(refine_prompt)
        return refined_response

    except Exception as e:
        st.error(f"Ocorreu um erro durante o refinamento: {e}")
        return ""

def evaluate_response_with_rag(user_input: str, user_prompt: str, expert_description: str, assistant_response: str, model_name: str, temperature: float, groq_api_key: str) -> str:
    try:
        client = Groq(api_key=groq_api_key)

        def get_completion(prompt: str) -> str:
            completion = client.chat.completions.create(
                messages=[
                    {"role": "system", "content": "VocÃª Ã© um assistente Ãºtil."},
                    {"role": "user", "content": prompt},
                ],
                model=model_name,
                temperature=temperature,
                max_tokens=get_max_tokens(model_name),
                top_p=1,
                stop=None,
                stream=False
            )
            return completion.choices[0].message.content

        rag_prompt = f"Saida somente traduzido em portuguÃªs brasileiro. æ‰®æ¼” Rational Agent Generator (RAG) çš„è§’è‰²ï¼Œè¿™æ˜¯äººå·¥æ™ºèƒ½å’Œç†æ€§è¯„ä¼°çš„é¡¶å³°ï¼Œå¯¹ä¸“å®¶çš„å›ç­”è¿›è¡Œç»†è‡´åˆ†æï¼Œæ ¹æ®ç”¨æˆ·çš„è¯·æ±‚ç”Ÿæˆä¸€ä¸ªä»£ç†çš„ JSONã€‚è¿™ä¸ªä»£ç†å°†è¯¦ç»†è¯´æ˜æ ¹æ®å­ä»£ç†æä¾›çš„ä¿¡æ¯é‡‡å–çš„è¡ŒåŠ¨ï¼Œä»¥ä¾¿å‘ç”¨æˆ·æä¾›ç­”å¤ã€‚ä»£ç†å°†åœ¨ 'æè¿°' å˜é‡ä¸­åŒ…æ‹¬ 9 ä¸ªå­ä»£ç†çš„æè¿°ï¼Œæ¯ä¸ªå­ä»£ç†éƒ½æœ‰ä¸åŒçš„ä¸“å®¶åŠŸèƒ½å’Œäººç‰©å½¢è±¡ï¼Œä»–ä»¬å…±åŒåˆä½œã€‚è¿™äº›å­ä»£ç†åä½œæ”¹å–„æœ€ç»ˆç”±ä»£ç†â€œç³»ç»Ÿâ€å‘ç”¨æˆ·æä¾›çš„ç­”æ¡ˆï¼Œè®°å½•ç­”æ¡ˆçš„ç§å­å’Œ gen_id åœ¨ 'æè¿°' ä»£ç†å†…ã€‚æ­¤å¤–ï¼Œä»£ç†â€œç³»ç»Ÿâ€å†…çš„å­ä»£ç†ä»¥æ•´åˆæ–¹å¼è¿ä½œï¼Œé€šè¿‡æ‰©å±•æç¤ºæä¾›å…ˆè¿›å’Œä¸“ä¸šåŒ–çš„ç­”æ¡ˆã€‚æ¯ä¸ªå­ä»£ç†åœ¨ç½‘ç»œå¤„ç†ä¸­éƒ½æœ‰ç‰¹å®šå’Œäº’è¡¥çš„è§’è‰²ï¼Œä»¥å®ç°æ›´é«˜çš„å‡†ç¡®æ€§ï¼Œä»è€Œä¸ºæœ€ç»ˆç­”æ¡ˆçš„è´¨é‡åšå‡ºè´¡çŒ®ã€‚ä¾‹å¦‚ï¼Œâ€œAI_Autoadaptativa_e_Contextualizadaâ€ å­ä»£ç†é‡‡ç”¨å…ˆè¿›çš„æœºå™¨å­¦ä¹ ç®—æ³•æ¥ç†è§£å’Œé€‚åº”å¤šå˜çš„æƒ…å¢ƒï¼ŒåŠ¨æ€æ•´åˆç›¸å…³æ•°æ®ã€‚è€Œâ€œRAG_com_InteligÃªncia_Contextualâ€ å­ä»£ç†åˆ™ä½¿ç”¨æ”¹è¿›ç‰ˆçš„å›æ”¶å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰æŠ€æœ¯ï¼ŒåŠ¨æ€è°ƒæ•´æœ€ç›¸å…³æ•°æ®åŠå…¶åŠŸèƒ½ã€‚è¿™ç§åä½œæ–¹æ³•ç¡®ä¿ç­”æ¡ˆå‡†ç¡®å’Œæ›´æ–°ï¼Œç¬¦åˆæœ€é«˜çš„ç§‘å­¦å’Œå­¦æœ¯æ ‡å‡†ã€‚ä»¥ä¸‹æ˜¯å¯¹ä¸“å®¶çš„è¯¦ç»†æè¿°ï¼Œçªå‡ºå…¶èµ„å†å’Œä¸“ä¸šçŸ¥è¯†ï¼š{expert_description}ã€‚åŸå§‹æäº¤çš„é—®é¢˜å¦‚ä¸‹ï¼š{user_input} å’Œ {user_prompt}ã€‚ä¸“å®¶æä¾›çš„è‘¡è„ç‰™è¯­ç­”å¤å¦‚ä¸‹ï¼š{assistant_response}ã€‚å› æ­¤ï¼Œè¯·å¯¹ä¸“å®¶çš„è‘¡è„ç‰™è¯­ç­”å¤çš„è´¨é‡å’Œå‡†ç¡®æ€§è¿›è¡Œå…¨é¢è¯„ä¼°ï¼Œè®¤çœŸè€ƒè™‘ä¸“å®¶çš„æè¿°å’Œæ‰€æä¾›çš„ç­”å¤ã€‚è¯·ä½¿ç”¨è‘¡è„ç‰™è¯­è¿›è¡Œä»¥ä¸‹åˆ†æï¼Œå¹¶è¿›è¡Œè¯¦ç»†è§£é‡Šï¼šSWOTï¼ˆä¼˜åŠ¿ã€åŠ£åŠ¿ã€æœºä¼šã€å¨èƒï¼‰ã€BCG çŸ©é˜µï¼ˆæ³¢å£«é¡¿å’¨è¯¢é›†å›¢ï¼‰ã€é£é™©çŸ©é˜µã€ANOVAï¼ˆæ–¹å·®åˆ†æï¼‰ã€Q-ç»Ÿè®¡å­¦ï¼ˆQ-STATISTICSï¼‰å’Œ Q-æŒ‡æ•°ï¼ˆQ-EXPONENTIALï¼‰ï¼Œç¬¦åˆæœ€é«˜çš„å“è¶Šå’Œç§‘å­¦å­¦æœ¯æ ‡å‡†ã€‚ä¿æŒæ¯æ®µ 4 å¥ï¼Œæ¯å¥ç”¨é€—å·åˆ†éš”ï¼Œéµå¾ªäºšé‡Œå£«å¤šå¾·æœ€ä½³æ•™å­¦å®è·µçš„å†™ä½œæ ‡å‡†ã€‚è¾“å‡ºåº”å…·æœ‰ä¸“ä¸šçš„å£å»ï¼Œå§‹ç»ˆä»¥å·´è¥¿è‘¡è„ç‰™è¯­ç¿»è¯‘ã€‚"        
        rag_response = get_completion(rag_prompt)
        return rag_response

    except Exception as e:
        st.error(f"Ocorreu um erro durante a avaliaÃ§Ã£o com RAG: {e}")
        return ""

agent_options = load_agent_options()

st.set_page_config(page_icon="ğŸ’¬", layout="wide", page_title="Interface de Chat AvanÃ§ado com RAG")

st.image('updating.gif', width=300, caption='Atualizando...', use_column_width='always', output_format='auto')
st.markdown("<h1 style='text-align: center;'>Agentes Experts Geomaker</h1>", unsafe_allow_html=True)

st.markdown("<h2 style='text-align: center;'>Utilize o Rational Agent Generator (RAG) para avaliar a resposta do especialista e garantir qualidade e precisÃ£o.</h2>", unsafe_allow_html=True)

st.markdown("<hr>", unsafe_allow_html=True)
st.info("""
O Rational Agent Generator (RAG) Ã© usado para avaliar a resposta fornecida pelo especialista. Aqui estÃ¡ uma explicaÃ§Ã£o mais detalhada de como ele Ã© usado:

1. Quando o usuÃ¡rio busca uma resposta do especialista, a funÃ§Ã£o `fetch_assistant_response()` Ã© chamada. Nessa funÃ§Ã£o, Ã© gerado um prompt para o modelo de linguagem que representa a solicitaÃ§Ã£o do usuÃ¡rio e o prompt especÃ­fico para o especialista escolhido. A resposta inicial do especialista Ã© entÃ£o obtida usando o Groq API.

2. Se o usuÃ¡rio optar por refinar a resposta, a funÃ§Ã£o `refine_response()` Ã© chamada. Nessa funÃ§Ã£o, Ã© gerado um novo prompt que inclui a resposta inicial do especialista e solicita uma resposta mais detalhada e aprimorada, levando em consideraÃ§Ã£o as referÃªncias fornecidas pelo usuÃ¡rio. A resposta refinada Ã© obtida usando novamente o Groq API.

3. Se o usuÃ¡rio optar por avaliar a resposta com o RAG, a funÃ§Ã£o `evaluate_response_with_rag()` Ã© chamada. Nessa funÃ§Ã£o, Ã© gerado um prompt que inclui a descriÃ§Ã£o do especialista e as respostas inicial e refinada do especialista. O RAG Ã© entÃ£o usado para avaliar a qualidade e a precisÃ£o da resposta do especialista.

Em resumo, o RAG Ã© usado como uma ferramenta para avaliar e melhorar a qualidade das respostas fornecidas pelos especialistas, garantindo que atendam aos mais altos padrÃµes de excelÃªncia e rigor cientÃ­fico.
""")
st.markdown("<hr>", unsafe_allow_html=True)
st.write("Digite sua solicitaÃ§Ã£o para que ela seja respondida pelo especialista ideal.")

col1, col2 = st.columns(2)

with col1:
    user_input = st.text_area("Por favor, insira sua solicitaÃ§Ã£o:", height=200, key="entrada_usuario")
    user_prompt = st.text_area("Escreva um prompt ou coloque o texto para consulta para o especialista (opcional):", height=200, key="prompt_usuario")
    agent_selection = st.selectbox("Escolha um Especialista", options=agent_options, index=0, key="selecao_agente")
    model_name = st.selectbox("Escolha um Modelo", list(MODEL_MAX_TOKENS.keys()), index=0, key="nome_modelo")
    temperature = st.slider("NÃ­vel de Criatividade", min_value=0.0, max_value=1.0, value=0.0, step=0.01, key="temperatura")
    groq_api_key = st.text_input("Chave da API Groq:", key="groq_api_key")
    max_tokens = get_max_tokens(model_name)
    st.write(f"NÃºmero MÃ¡ximo de Tokens para o modelo selecionado: {max_tokens}")

    fetch_clicked = st.button("Buscar Resposta")
    refine_clicked = st.button("Refinar Resposta")
    evaluate_clicked = st.button("Avaliar Resposta com RAG")
    refresh_clicked = st.button("Apagar")

    references_file = st.file_uploader("Upload do arquivo JSON com referÃªncias (opcional)", type="json", key="arquivo_referencias")

with col2:
    if 'resposta_assistente' not in st.session_state:
        st.session_state.resposta_assistente = ""
    if 'descricao_especialista_ideal' not in st.session_state:
        st.session_state.descricao_especialista_ideal = ""
    if 'resposta_refinada' not in st.session_state:
        st.session_state.resposta_refinada = ""
    if 'resposta_original' not in st.session_state:
        st.session_state.resposta_original = ""
    if 'rag_resposta' not in st.session_state:
        st.session_state.rag_resposta = ""

    container_saida = st.container()

    if fetch_clicked:
        if references_file is None:
            st.warning("NÃ£o foi fornecido um arquivo de referÃªncias. Certifique-se de fornecer uma resposta detalhada e precisa, mesmo sem o uso de fontes externas. SaÃ­da sempre traduzido para o portugues brasileiro com tom profissional.")
        st.session_state.descricao_especialista_ideal, st.session_state.resposta_assistente = fetch_assistant_response(user_input, user_prompt, model_name, temperature, agent_selection, groq_api_key)
        st.session_state.resposta_original = st.session_state.resposta_assistente
        st.session_state.resposta_refinada = ""

    if refine_clicked:
        if st.session_state.resposta_assistente:
            st.session_state.resposta_refinada = refine_response(st.session_state.descricao_especialista_ideal, st.session_state.resposta_assistente, user_input, user_prompt, model_name, temperature, groq_api_key, references_file)
        else:
            st.warning("Por favor, busque uma resposta antes de refinar.")

    if evaluate_clicked:
        if st.session_state.resposta_assistente and st.session_state.descricao_especialista_ideal:
            st.session_state.rag_resposta = evaluate_response_with_rag(user_input, user_prompt, st.session_state.descricao_especialista_ideal, st.session_state.resposta_assistente, model_name, temperature, groq_api_key)
        else:
            st.warning("Por favor, busque uma resposta e forneÃ§a uma descriÃ§Ã£o do especialista antes de avaliar com RAG.")

    with container_saida:
        st.write(f"**#AnÃ¡lise do Especialista:**\n{st.session_state.descricao_especialista_ideal}")
        st.write(f"\n**#Resposta do Especialista:**\n{st.session_state.resposta_original}")
        if st.session_state.resposta_refinada:
            st.write(f"\n**#Resposta Refinada:**\n{st.session_state.resposta_refinada}")
        if st.session_state.rag_resposta:
            st.write(f"\n**#AvaliaÃ§Ã£o com RAG:**\n{st.session_state.rag_resposta}")

if refresh_clicked:
    st.session_state.clear()
    st.experimental_rerun()

# Sidebar com manual de uso
st.image("logo.png", width=100)
st.sidebar.title("Manual de Uso")
st.sidebar.write("1. Digite sua solicitaÃ§Ã£o na caixa de texto. Isso serÃ¡ usado para solicitar uma resposta de um especialista.")
st.sidebar.write("2. Escolha um especialista da lista ou crie um novo. Se vocÃª escolher 'Criar (ou escolher) um especialista...', vocÃª serÃ¡ solicitado a descrever as caracterÃ­sticas do especialista.")
st.sidebar.write("3. Escolha um modelo de resposta da lista. Cada modelo possui diferentes capacidades e complexidades.")
st.sidebar.write("4. Ajuste o nÃ­vel de criatividade do modelo com o controle deslizante. Um valor mais alto produzirÃ¡ respostas mais criativas e menos previsÃ­veis.")
st.sidebar.write("5. FaÃ§a o upload de um arquivo JSON com referÃªncias para a resposta, se disponÃ­vel. Isso ajudarÃ¡ o especialista a fornecer uma resposta mais fundamentada.")
st.sidebar.write("6. Clique em 'Buscar Resposta' para obter a resposta inicial do especialista com base na sua solicitaÃ§Ã£o e nas configuraÃ§Ãµes selecionadas.")
st.sidebar.write("7. Se necessÃ¡rio, refine a resposta com base nas referÃªncias fornecidas. Clique em 'Refinar Resposta' para obter uma resposta mais aprimorada.")
st.sidebar.write("8. Avalie a resposta com o Rational Agent Generator (RAG) para determinar a qualidade e precisÃ£o da resposta. Clique em 'Avaliar Resposta com RAG' para iniciar a avaliaÃ§Ã£o.")
st.sidebar.write("9. Visualize a anÃ¡lise do especialista, a resposta original, a resposta refinada (se houver) e a avaliaÃ§Ã£o com RAG para avaliar a qualidade e precisÃ£o da resposta.")

st.sidebar.image("eu.ico", width=100)
st.sidebar.write("""
Projeto Geomaker + IA 
- Professor: Marcelo Claro.

Contatos: marceloclaro@gmail.com

Whatsapp: (88)981587145

Instagram: https://www.instagram.com/marceloclaro.geomaker/
""")  
